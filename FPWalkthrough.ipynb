{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Floating Point Issues in Computation\n",
    "## This notebook is a walkthrough and tutorial of floating point related topics, largely inspired (and closely following) the paper described below:\n",
    "\n",
    "Link: http://www.validlab.com/goldberg/paper.ps Summary from the paper \"Note – This document is an edited reprint of the paper What Every Computer Scientist Should Know About Floating-Point Arithmetic, by David Goldberg, published in the March, 1991 issue of Computing Surveys. Copyright 1991, Association for Computing Machinery, Inc., reprinted by permission.\"\n",
    "\n",
    "More details available from:\n",
    "http://grouper.ieee.org/groups/754/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The notebook organization will largely mirror the scheme from the above paper\n",
    "- Motivation\n",
    "- Part I: Rounding Errors\n",
    "- Part II: IEEE 754 Standard\n",
    "- Part III: Details (and other issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "As implied in the title of the key reference \"What Every Computer Scientist Should Know About Floating-Point Arithmetic\" having a working understanding about this topic seems to be fundamental to essentially anyone working with computation.  Even though the details might be somewhat hidden inside the hardware and software implementations, the issues should be understood since they can manifest in various ways in practice.  This notebook attempts to extract key ideas from the reference(s) and provide some exercises to gain some familiarity with the points raised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Rounding Errors\n",
    "Rounding Error:\n",
    "Basic problem.  Infinite number of real numbers, finite number of bits.\n",
    "Guard digits for differences of two close real-numbers (floating point).\n",
    "\n",
    "Real number → Representable by a floating point representation (but sometimes not exactly)\n",
    "When exact, it is called a floating point number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic representation \n",
    "\n",
    "$ \\pm d_0.d_1 d_2 d_3 d_4 d_{p-1} \\times \\beta^e$ represents the number\n",
    "$ \\pm ( d_0+d_1 \\beta^{-1} + \\ldots + d_{p-1} \\beta^{-(p-1)} ) \\beta^e $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Show that the number of bits required to encode the above number is\n",
    "$ \\lceil log_{2} (e_{max}-e_{min}+1) \\rceil + \\lceil log_{2}\\beta^{p} \\rceil + 1 $  \n",
    "where $\\lceil x \\rceil$ is the ceiling function applied to $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "We require that $2^{N} > R$, where $N$ is the number of bit we require and $R$ is the real number we are trying to represent using binary.  \n",
    "Taking the base 2 logarithm of both sides yields:\n",
    "$N > log_2 R$.  If we take the ceiling of the right hand side \n",
    "(the smallest integer such that the inequality is satisfied)\n",
    "we obtain the desired result shown in the theory.  The additional 1 comes from the bit needed for representing the sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_bits_exponent =  4.0\n",
      "num_bits_significand =  14.0\n",
      "num_bits_sign =  1\n",
      "total_bits =  19.0\n"
     ]
    }
   ],
   "source": [
    "# Exploration code:\n",
    "# Example of bits required\n",
    "import numpy as np\n",
    "emax =  5  \n",
    "emin = -4\n",
    "beta = 10 # base10\n",
    "p = 4     # four figures\n",
    "\n",
    "#TODO:  Implement the theory into the missing python code\n",
    "num_bits_exponent = np.ceil(np.log2(emax-emin+1))\n",
    "num_bits_significand = np.ceil(np.log2(beta**p))\n",
    "num_bits_sign = 1\n",
    "total_bits = num_bits_exponent + num_bits_significand + num_bits_sign\n",
    "\n",
    "print('num_bits_exponent = ', num_bits_exponent)\n",
    "print('num_bits_significand = ', num_bits_significand)\n",
    "print('num_bits_sign = ', num_bits_sign)\n",
    "print('total_bits = ', total_bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Representation\n",
    "When the number starts with a 1, this is called \"normalized\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Show that if beta=2, p=3, emin=-1 and emax=2, there are 16 normalized numbers that can be represented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "p = 3:\n",
    "100\n",
    "101\n",
    "110\n",
    "111\n",
    "Each have beta(-1), beta(0), beta(1), and beta(2)  - 4 exponents\n",
    "Therefore we have 4x4 = 16 possible normalized numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Given  that the representation:\n",
    "$ \\pm d_0.d_1 d_2 d_3 d_4 d_{p-1} \\times \\beta^e$ represents the number\n",
    "$ \\pm ( d_0+d_1 \\beta^{-1} + \\ldots + d_{p-1} \\beta^{-(p-1)} ) \\beta^e $\n",
    "\n",
    "Write down what each of the 16 normalized encoding represent in decimal numbers (assume all positive).  Recall that for decimal (base 10), we would have a representation like this for the number 120\n",
    "\n",
    "$1.20 \\times 10^2 = 120 = 1 \\times 10^0(10^2) + 2 \\times 10^{-1}(10^2) + 0 \\times 10^{-2}(10^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "(exponent = -1.  Encoded as 00)  \n",
    "100 : 00  = $1 \\times 2^{0} 2^{-1} + 0 \\times 2^{-1} 2^{-1} + 0 \\times 2^{-2} 2^{-1} = 0.5$  \n",
    "101 : 00  = $1 \\times 2^{0} 2^{-1} + 0 \\times 2^{-1} 2^{-1} + 1 \\times 2^{-2} 2^{-1} = 0.5 + 0.125 = 0.625$  \n",
    "110 : 00  \n",
    "111 : 00  \n",
    "\n",
    "(exponent = 0.  Encoded as 01)  \n",
    "100 : 01   =   \n",
    "101 : 01  \n",
    "110 : 01  \n",
    "111 : 01  \n",
    "\n",
    "(exponent = 0.  Encoded as 10)  \n",
    "100 : 10  \n",
    "101 : 10  \n",
    "110 : 10  \n",
    "111 : 10  \n",
    "\n",
    "(exponent = 1.  Encoded as 11)  \n",
    "100 : 11  \n",
    "101 : 11  \n",
    "110 : 11  \n",
    "111 : 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.625\n",
      "0.75\n",
      "0.875\n",
      "\n",
      "1.0\n",
      "1.25\n",
      "1.5\n",
      "1.75\n",
      "\n",
      "2.0\n",
      "2.5\n",
      "3.0\n",
      "3.5\n",
      "\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise for normalized numbers\n",
    "import numpy as np\n",
    "\n",
    "# We want to generate the decimal equivalent of the above encodings:\n",
    "def normalized2decimal(prefix, exponent, base):\n",
    "    \n",
    "    res = 0\n",
    "    pos = 0\n",
    "    for iSym in prefix:\n",
    "        res = res+ 1.0*int(iSym)*(base**pos)*base**(exponent)\n",
    "        pos = pos-1\n",
    "        \n",
    "    return res\n",
    "\n",
    "# Try out some cases:\n",
    "\n",
    "print(normalized2decimal('100',-1,2))\n",
    "print(normalized2decimal('101',-1,2))\n",
    "print(normalized2decimal('110',-1,2))\n",
    "print(normalized2decimal('111',-1,2))\n",
    "print()\n",
    "print(normalized2decimal('100',0,2))\n",
    "print(normalized2decimal('101',0,2))\n",
    "print(normalized2decimal('110',0,2))\n",
    "print(normalized2decimal('111',0,2))\n",
    "print()\n",
    "print(normalized2decimal('100',1,2))\n",
    "print(normalized2decimal('101',1,2))\n",
    "print(normalized2decimal('110',1,2))\n",
    "print(normalized2decimal('111',1,2))\n",
    "print()\n",
    "print(normalized2decimal('100',2,2))\n",
    "print(normalized2decimal('101',2,2))\n",
    "print(normalized2decimal('110',2,2))\n",
    "print(normalized2decimal('111',2,2))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the normalized representation, the number zero has a special challenge because of the requirement to have a leading one.  Therefore, a special encoding is used.  One of the exponents is reserved to represent (or indicate) the number zero.  Therefore, continuing the earlier representation scheme, here is the complete list of 16 normalized numbers with zero included.  The exponent bits are shown to the right of the colon symbol below.  Notice that the exponent range is reduced by one to accomodate the encoding for zero. \n",
    "\n",
    "(special zero exponent = -2.  Encoded as 00)    \n",
    "100 : 00  = Zero    \n",
    "101 : 00  = Not valid  \n",
    "110 : 00  = Not valid  \n",
    "111 : 00  = Not valid  \n",
    "\n",
    "(exponent = -1. Encoded as 01)  \n",
    "100 : 01  = $1 \\times 2^{0} 2^{-1} + 0 \\times 2^{-1} 2^{-1} + 0 \\times 2^{-2} 2^{-1} = 0.5$    \n",
    "101 : 01  = $1 \\times 2^{0} 2^{-1} + 0 \\times 2^{-1} 2^{-1} + 1 \\times 2^{-2} 2^{-1} = 0.5 + 0.125 = 0.625$     \n",
    "110 : 01  \n",
    "111 : 01  \n",
    "\n",
    "(exponent = 0. Encoded as 10)  \n",
    "100 : 10 =  \n",
    "101 : 10  \n",
    "110 : 10  \n",
    "111 : 10  \n",
    "\n",
    "(exponent = 1. Encoded as 11)  \n",
    "100 : 11 = \n",
    "101 : 11  \n",
    "110 : 11  \n",
    "111 : 11  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Error, Units in the Last Place (ULPs), Machine Epsilon\n",
    "\n",
    "At this point, the general theme should be emerging in that an arbitrary real number (\"infinite precision\") is approximated in the computed by a floating point representation.  There are gaps between each floating point representation when compared to the real-numbers, such that a given real number may fall between two floating point representations and thus, will need to either be assigned to the lower one or the upper one.  Thus, the error is bounded to be no more than $\\frac{1}{2}$ of the spacing at that particular interval, which from the above analysis is clearly not uniform, but depends on the exponent that applies in that particular range.\n",
    "\n",
    "There is an ultimate limit to this, which is known as *machine epsilon*, $\\epsilon$, which is the smallest interval that can be represented by the machine implementation.\n",
    "\n",
    "The *units in the last place* (ulps) is absolute error between the real number in question and the closest floating point number.  For example, consider 0.03412 as the real number, and 0.034 as the floating point representation (assuming for a moment this number can be represented as shown).  Then we have $0.03412-0.034=0.12ulps$.\n",
    "\n",
    "*Relative error* is this difference, divided by the real number itself.  So in this case, we would have $\\frac{0.00012}{0.03412}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation Gap\n",
    "Issue with 0.1:  \n",
    "(1/2.0)**3  \n",
    "Out[28]: 0.125  \n",
    "(1/2.0)**4  \n",
    "Out[29]: 0.0625  \n",
    "\n",
    "\n",
    "## Fractional Error  \n",
    "1.01  \n",
    "0.99(3)  \n",
    "0.02  \n",
    "Actual answer is 0.017  \n",
    "0.003/0.017  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: IEEE 754\n",
    "\n",
    "Discussion of the floating point standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Details (and other issues)\n",
    "\n",
    "Hardware/Software impementation and other issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
